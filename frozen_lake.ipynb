{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.envs.toy_text.frozen_lake import FrozenLakeEnv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def render_custom_map(custom_map):\n",
    "    env = FrozenLakeEnv(desc=custom_map, is_slippery=False, render_mode='rgb_array')\n",
    "    env.reset()\n",
    "    a = env.render()\n",
    "    return a\n",
    "\n",
    "# Example usage with the baseline map\n",
    "baseline_map = [\n",
    "    'SFFF',\n",
    "    'FHFH',\n",
    "    'FFFH',\n",
    "    'HFFG'\n",
    "]\n",
    "\n",
    "plt.imshow(render_custom_map(baseline_map))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = {\n",
    "    \"Baseline\": [\n",
    "        'SFFF',\n",
    "        'FHFH',\n",
    "        'FFFH',\n",
    "        'HFFG'\n",
    "    ],\n",
    "    \"Map 2.1\": [\n",
    "        'SFFF',\n",
    "        'FHFH',\n",
    "        'FFFH',\n",
    "        'HFGF'\n",
    "    ],\n",
    "    \"Map 2.2\": [\n",
    "        'SFFF',\n",
    "        'FHFH',\n",
    "        'FGFH',\n",
    "        'HFFF'\n",
    "    ],\n",
    "    \"Map 2.3\": [\n",
    "        'SFFG',\n",
    "        'FHFH',\n",
    "        'FFFH',\n",
    "        'HFFF'\n",
    "    ],\n",
    "    \"Map 3.1\": [\n",
    "        'SFFF',\n",
    "        'HHFH',\n",
    "        'FHFH',\n",
    "        'HFFG'\n",
    "    ],\n",
    "    \"Map 3.2\": [\n",
    "        'SFFF',\n",
    "        'FHHH',\n",
    "        'FFFF',\n",
    "        'HHFG'\n",
    "    ],\n",
    "    \"Map 3.3\": [\n",
    "        'SFFH',\n",
    "        'HFFF',\n",
    "        'FFHH',\n",
    "        'HFFG'\n",
    "    ],\n",
    "    \"Map 4.1\": [\n",
    "        'FFFS',\n",
    "        'HFHF',\n",
    "        'FHHF',\n",
    "        'GFFF'\n",
    "    ],\n",
    "    \"Map 4.2\": [\n",
    "        'FFFG',\n",
    "        'HFHF',\n",
    "        'HHFF',\n",
    "        'SFFF'\n",
    "    ],\n",
    "    \"Map 4.3\": [\n",
    "        'FFFF',\n",
    "        'FHHS',\n",
    "        'FHFH',\n",
    "        'FFFG'\n",
    "    ],\n",
    "    \"Map 5.1\": [\n",
    "        'FFFFS',\n",
    "        'HFFFH',\n",
    "        'FFHFH',\n",
    "        'HFHFH',\n",
    "        'HGFFF'\n",
    "    ],\n",
    "    \"Map 5.2\": [\n",
    "        'FFFFFG',\n",
    "        'FFFHHF',\n",
    "        'FHFFFF',\n",
    "        'HFFHFF',\n",
    "        'HHFFFH',\n",
    "        'FSFFFF'\n",
    "    ],\n",
    "    \"Map 5.3\": [\n",
    "        'HFG',\n",
    "        'HFH',\n",
    "        'FFS'\n",
    "    ]\n",
    "}\n",
    "import pickle\n",
    "with open('maps.pkl', 'wb') as f:\n",
    "    pickle.dump(maps, f) \n",
    "\n",
    "for name, custom_map in maps.items():\n",
    "    plt.title(f\"\\nRendering {name}\")\n",
    "    plt.imshow(render_custom_map(custom_map))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def KL_divergence(policy_net_1, policy_net_2, states):\n",
    "    \"\"\"\n",
    "    Compute the KL divergence between two policies for a given state.\n",
    "    \n",
    "    :param policy_net_1: Policy network 1.\n",
    "    :param policy_net_2: Policy network 2.\n",
    "    :param states: State for which to compute the KL divergence.\n",
    "    :return: average KL divergence between the two policies.\n",
    "    \"\"\"\n",
    "    # Get the action probabilities for the two policies\n",
    "    action_probs_1 = policy_net_1.predict_proba(states) # #states x #actions\n",
    "    action_probs_2 = policy_net_2.predict_proba(states)\n",
    "    \n",
    "    action_probs_1 = np.clip(action_probs_1, 1e-10, 1.0)\n",
    "    action_probs_2 = np.clip(action_probs_2, 1e-10, 1.0)\n",
    "\n",
    "    kl_divergence = np.sum(action_probs_1 * np.log(action_probs_1 / action_probs_2), axis=1)\n",
    "\n",
    "    # Compute the KL divergence\n",
    "    print(kl_divergence.shape)\n",
    "    return np.mean(kl_divergence)\n",
    "\n",
    "def get_all_states(map_name):\n",
    "    \"\"\"\n",
    "    Get all the states in the environment.\n",
    "    \n",
    "    :param env: Environment.\n",
    "    :return: List of all states.\n",
    "    \"\"\"\n",
    "\n",
    "    env = create_custom_env(map_name)\n",
    "    all_states = np.arange(env.observation_space.n)\n",
    "    return all_states\n",
    "\n",
    "def create_custom_env(map_name):\n",
    "    \"\"\"\n",
    "    Create a custom environment.\n",
    "    \n",
    "    :param map_name: Name of the custom map.\n",
    "    :return: Environment.\n",
    "    \"\"\"\n",
    "    env = FrozenLakeEnv(desc=map_name, is_slippery=False)\n",
    "    return env\n",
    "\n",
    "\n",
    "env = create_custom_env(maps[\"Baseline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gym.envs.toy_text import frozen_lake\n",
    "\n",
    "e = frozen_lake.FrozenLakeEnv()\n",
    "e.observation_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = get_all_states(maps[\"Baseline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PPO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m policy_1 \u001b[38;5;241m=\u001b[39m \u001b[43mPPO\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mppo_frozenlake_Map 2.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m policy_2 \u001b[38;5;241m=\u001b[39m PPO\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mppo_frozenlake_Map 2.2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m kl_divergence \u001b[38;5;241m=\u001b[39m KL_divergence(policy_1, policy_2, states)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PPO' is not defined"
     ]
    }
   ],
   "source": [
    "policy_1 = PPO.load(\"ppo_frozenlake_Map 2.1\")\n",
    "policy_2 = PPO.load(\"ppo_frozenlake_Map 2.2\")\n",
    "\n",
    "kl_divergence = KL_divergence(policy_1, policy_2, states)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchwala",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
